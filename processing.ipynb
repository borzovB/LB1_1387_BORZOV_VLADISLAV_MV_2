import pylab as plt
import pandas as pd
import numpy as np
import seaborn as sns
from IPython.display import display

print("НАЧАЛО РАБОТЫ!")
#%%
print("Загрузка датасета")
# Загрузка файла
df = pd.read_csv("data/pdb_data_no_dups.csv")
#%%
print(f"Число строк и столбцов в датасете: {df.shape}")
#%%
print("Типы переменных.")
df.dtypes
#%%
print("Полная статистика для всех столбцов.")
df.describe(include="all")
#%%
print("Определение числа пустых переменных")
df.isnull().sum()
#%%
print("Пример заполнения данных")
df.head()
#%%
print("Доля пустых переменных для каждой переменной")
columns_to_check = [
    'structureId', 'classification', 'experimentalTechnique',
    'macromoleculeType', 'residueCount', 'resolution',
    'structureMolecularWeight', 'crystallizationMethod',
    'crystallizationTempK', 'densityMatthews',
    'densityPercentSol', 'pdbxDetails', 'phValue', 'publicationYear'
]

for col in columns_to_check:
    if col in df.columns:
        count = df[col].isnull().sum()
        pct = (count / len(df)) * 100
        print(f"{col:<25} → {pct:6.2f}%")
#%%
print("Удаление лишних столбцов")
df=df.drop(['publicationYear', 'structureId','pdbxDetails'], axis = 1)

print("\nОпределение категориальных и числовых переменных")
numeric_cols = df.select_dtypes(include='number').columns
categorical_cols = df.select_dtypes(include='object').columns

print(f"Числовые переменные: {numeric_cols}")
print(f"Категориальные переменные: {categorical_cols}")
#%%
# Масштабирования диапазона на графике
scales = {
    'phValue': (0, 14),
    'crystallizationTempK': (250, 350),
    'resolution': (0, 10),
    'densityMatthews': (1, 5),
    'densityPercentSol': (20, 80),
    'residueCount': (0, 3000),
    'structureMolecularWeight': (0, 1e6),
}

fig, axes = plt.subplots(3, 3, figsize=(16, 12))
axes = axes.ravel()
fig.suptitle("Гистограммы числовых признаков (с физическим масштабом)", fontsize=16, y=0.98)

for idx, col in enumerate(numeric_cols):
    ax = axes[idx]
    range_val = scales.get(col, (None, None))
    df[col].hist(bins=50, ax=ax, range=range_val, edgecolor='black', color='lightblue')
    ax.set_title(col)
    ax.set_xlabel(col)
    ax.set_ylabel("Количество")
    ax.grid(False)

for idx in range(len(numeric_cols), 9):
    axes[idx].set_visible(False)

plt.tight_layout()
plt.show()

# Ящики с усами
for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    df[[col]].boxplot()
    plt.title(f"Выбросы: {col}")
    plt.show()

# Гистограммы категориальных переменных по классам
for col in categorical_cols:
    if col in df.columns:
        plt.figure(figsize=(10, 5))
        top10 = df[col].value_counts().head(10)
        top10.plot(kind='bar')
        plt.title(f"Топ-10 значений: {col}")
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()
#%%
# Доли классов в каждой категориальной переменной
for col in categorical_cols:
    # Считаем частоты
    vc = df[col].value_counts().reset_index()
    vc.columns = ['Значение', 'Количество']
    vc['Доля, %'] = (vc['Количество'] / len(df) * 100).round(2)

    # Сортируем по убыванию
    vc = vc.sort_values('Количество', ascending=False)

    # Выводим заголовок и таблицу
    print(f"\n {col.upper()} (всего уникальных: {df[col].nunique()})")
    display(vc)
#%%
print("\nМатрица корреляций...")
corr_matrix = df[df.select_dtypes(include='number').columns].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt=".2f")
plt.title("Матрица корреляций числовых признаков")
plt.tight_layout()
plt.show()
#%%
print("\nДиаграмма рассеивания")

sns.pairplot(df[df.select_dtypes(include='number').columns], plot_kws={'alpha': 0.7})
plt.suptitle("Pairplot всех попарных диаграмм рассеяния", y=1.02)
plt.show()
#%%
print("Удаление лишних столбцов")
df=df.drop(['macromoleculeType', 'densityMatthews'], axis = 1)
#%%
print(f"Количество дублирующих строк: {df.duplicated().sum()}")
#%%
print(f"Число строк и столбцов в датасете: {df.shape}")
#%%
print("Удаление дубликатов.")
df = df.drop_duplicates().reset_index(drop=True)
print(f"Количество дублирующих строк: {df.duplicated().sum()}")
#%%
print(f"Число строк и столбцов в датасете: {df.shape}")
#%%
df.isnull().sum()

#%%
print("Заполняем пустые значения для строк модой")
for col in df.select_dtypes(include=['object', 'category']).columns:
    df[col] = df[col].fillna(df[col].mode()[0])
#%%
df.isnull().sum()
#%%
# Линейная регрессия будет применяться для генерации значений
from LinearRegression import LinearRegression
print("Начать починку!")
df_fild = df.copy() # Копируем таблицу, чтобы избежать ненужного изменения данных
number = df.select_dtypes(include='number').columns.tolist() # Получение наименований числовых столбцов из датасета

for n in range(5): # Проводим 5 итераций, это позволяет лучше нормализовать данные, чтобы при заполнении данными пустых ячеек
    # не сгенерировать значения увеличивающие разбалансировку, например, чтобы между числами не было сильного разрыва
    for column in number:
        # Начало генерации данных для каждого столбца
        df_no_null = df_fild[df_fild[column].notnull()].copy() # Выявление строк, где нет пустых значений, они понадобятся для обучения модели это хорошие данные необходимы для обучения модели
        df_null = df_fild[df_fild[column].isnull()].copy() # Выявление строк с пустыми ячейками, прохие данные

        if df_null.empty:
            # Если в столбце нет пустых ячеек, то пропускаем его обработку
            continue

        fact_column = [col for col in number if col!=column] # Подготавливаем данные выявляем все столбцы кроме обрабатываемого, они будут необходимы для обучения модели
        X = df_no_null[fact_column].copy() # Данные из хороших строк, необходимы для обучения модели
        for nice in fact_column:
            X[nice] = X[nice].fillna(X[nice].mean())
            # Заполняем данные для обучения средними значениями

        y = df_no_null[column].values
        # Целевая переменная без NaN


        X_try = df_null[fact_column].copy() # Данные из плохих строк, необходимы
        # для дальнейшего заполнения
        for bed in fact_column:
            X_try[bed] = X_try[bed].fillna(X[bed].mean()) # Временно заполняем средними значениями взятые из хороших данных

        mean = np.mean(X, axis=0) # Среднее значение по столбцам
        std = np.std(X, axis=0) # Разброс значений по столбцам
        std[std == 0] = 1 # Если разброс значений 0, то необходимо заполнить пустые значений 1, чтобы нормализация прошла

        X = (X-mean)/std
        X_try = (X_try-mean)/std

        li = LinearRegression()
        li.fit(X,y)
        predicted_values = li.predict(X_try)

        df_fild.loc[df_fild[column].isnull(), column] = predicted_values # Записываем угаданные значения в пустые клетки
        df = df_fild
#%%
df.isnull().sum()
#%%
numeric_cols = df.select_dtypes(include='number').columns
df_model = df.copy()

for col in numeric_cols:
    Q1 = df_model[col].quantile(0.25)
    Q3 = df_model[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_model = df_model[(df_model[col] >= lower_bound) & (df_model[col] <= upper_bound)]

print(f"Количество строк после удаления выбросов: {len(df_model)}")
#%%
print("ЯЩИК С УСАМИ ПОСЛЕ ОБРАБОТКИ ")
for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    df_model[[col]].boxplot()
    plt.title(f"Выбросы: {col}")
    plt.show()
#%%
scales = {
    'phValue': (0, 14),
    'crystallizationTempK': (250, 350),
    'resolution': (0, 10),
    'densityMatthews': (1, 5),
    'densityPercentSol': (20, 80),
    'residueCount': (0, 3000),
    'structureMolecularWeight': (0, 1e6),
}

fig, axes = plt.subplots(3, 3, figsize=(16, 12))
axes = axes.ravel()
fig.suptitle("Гистограммы числовых признаков (с физическим масштабом)", fontsize=16, y=0.98)

for idx, col in enumerate(numeric_cols):
    ax = axes[idx]
    range_val = scales.get(col, (None, None))
    df_model[col].hist(bins=50, ax=ax, range=range_val, edgecolor='black', color='lightblue')
    ax.set_title(col)
    ax.set_xlabel(col)
    ax.set_ylabel("Количество")
    ax.grid(False)

for idx in range(len(numeric_cols), 9):
    axes[idx].set_visible(False)

plt.tight_layout()
plt.show()

# Гистограммы категориальных
for col in categorical_cols:
    if col in df_model.columns:
        plt.figure(figsize=(10, 5))
        top10 = df_model[col].value_counts().head(10)
        top10.plot(kind='bar')
        plt.title(f"Топ-10 значений: {col}")
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()
#%%
corr_matrix = df_model[df_model.select_dtypes(include='number').columns].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt=".2f")
plt.title("Матрица корреляций числовых признаков")
plt.tight_layout()
plt.show()
#%%
sns.pairplot(df_model[df_model.select_dtypes(include='number').columns], plot_kws={'alpha': 0.7})
plt.suptitle("Pairplot всех попарных диаграмм рассеяния", y=1.02)
plt.show()
#%%
df_model['classification'].nunique()
#%%
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
import pandas as pd

print("Подготовка данных для балансировки...")

# Задаём минимальный и максимальный порог
min_class_count = 100
max_class_count = 4051

# Создаем копию данных
df_filtered = df_model.copy()

# Считаем количество строк по классам
class_counts = df_filtered['classification'].value_counts()

# Определяем, какие классы оставить
good_classes = class_counts[(class_counts >= min_class_count) & (class_counts <= max_class_count)].index.tolist()
rare_classes = class_counts[class_counts < min_class_count].index.tolist()
frequent_classes = class_counts[class_counts > max_class_count].index.tolist()

print(f"Редких классов (<{min_class_count} samples): {len(rare_classes)}")
print(f"Слишком частых классов (>{max_class_count} samples): {len(frequent_classes)}")
print(f"Классов для сохранения: {len(good_classes)}")

# Фильтруем
df_filtered = df_filtered[df_filtered['classification'].isin(good_classes)]

print("Распределение после фильтрации:")
print(df_filtered['classification'].value_counts())
print(f"Осталось классов: {df_filtered['classification'].nunique()}")
print(f"Осталось строк: {len(df_filtered)}")

# Балансировка
print("\nБалансировка классов...")

# Создаем X и y из отфильтрованных данных
X = df_filtered.drop(columns=['classification'])
y = df_filtered['classification']

print(f"Тип y: {type(y.iloc[0])}")
print(f"Уникальные классы: {y.unique()[:5]}...")  # первые 5 классов
print(f"Всего классов после фильтрации: {y.nunique()}")

# Балансировка классов
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# Превращаем обратно в DataFrame/Series
X_resampled = pd.DataFrame(X_resampled, columns=X.columns)
y_resampled = pd.Series(y_resampled, name='classification')

print("После балансировки:")
print(y_resampled.value_counts())
print(f"Итоговое количество классов: {y_resampled.nunique()}")
print(f"Итоговый размер датасета: {len(X_resampled)}")

print("\nКодирование данных для ML...")

# Объединяем сбалансированные данные
df_balanced = X_resampled.copy()
df_balanced['classification'] = y_resampled

# Кодируем категориальные признаки
categorical_cols = df_balanced.select_dtypes(include='object').columns

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df_balanced[col] = le.fit_transform(df_balanced[col].astype(str))
    label_encoders[col] = le
    print(f"Закодирован: {col}")

# Проверяем результат
print(f"\nТипы данных после кодирования:")
print(df_balanced.dtypes)

# Создаем финальные X и y
X_final = df_balanced.drop(columns=['classification'])
y_final = df_balanced['classification']
#%%
df_balanced.head()
#%%
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
#%%
print(f"Число всех строк в датасете: {len(X_final)}")
#%%
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.utils import resample

desired_total = 20000
train_ratio = 0.95

sample_size_train = int(desired_total * train_ratio)
sample_size_test = desired_total - sample_size_train

print(f"\nСтрок: {desired_total:,} всего!")
print(f"  • Train: {sample_size_train:,} ({train_ratio:.0%})")
print(f"  • Test:  {sample_size_test:,} ({1-train_ratio:.0%})")

X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X_final, y_final,
    test_size=1-train_ratio,
    random_state=42,
    stratify=y_final
)

X_train_small, y_train_small = resample(
    X_train_full, y_train_full,
    n_samples=sample_size_train,
    random_state=42,
    stratify=y_train_full
)

X_test_small, y_test_small = resample(
    X_test_full, y_test_full,
    n_samples=sample_size_test,
    random_state=42,
    stratify=y_test_full
)

total_small = len(X_train_small) + len(X_test_small)
print(f"\nПодвыборка готова: {total_small:,} строк!")
print(f"   X_train_small: {X_train_small.shape}")
print(f"   X_test_small:  {X_test_small.shape}")
#%%
from sklearn.preprocessing import StandardScaler

print("Применяем нормализацию данных")

# Создаем scaler и нормализуем данные
scaler = StandardScaler()

# Нормализуем тренировочные данные
X_train_small_scaled = scaler.fit_transform(X_train_small)

# Нормализуем тестовые данные (используя параметры с тренировочных)
X_test_small_scaled = scaler.transform(X_test_small)

#%%
# Подбор оптимального k
param_grid = {'n_neighbors': range(1, 10)}
knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
knn.fit(X_train_small_scaled, y_train_small)

print("Лучший параметр k:", knn.best_params_)

# Оценка
y_pred_knn = knn.predict(X_test_small_scaled)
print("\nKNN — отчёт классификации:")
print(classification_report(y_test_small, y_pred_knn))
#%%
selected_classes = sorted(y_train_small.unique()[:20])
print(f"Выбранные классы: {selected_classes}")

mask = np.isin(y_test_small, selected_classes)
y_test_5 = y_test_small[mask]
y_pred_5 = y_pred_knn[mask]

cm = confusion_matrix(y_test_5, y_pred_5, labels=selected_classes)
print("\nМатрица ошибок (ТОЛЬКО 20 классов):")
print(cm)

# === КРАСИВАЙ HEATMAP (5x5) ===
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=selected_classes,
            yticklabels=selected_classes,
            linewidths=0.5, linecolor='gray')
plt.title("Матрица ошибок KNN (ТОЛЬКО 20 классов)")
plt.xlabel("Предсказано")
plt.ylabel("Истинно")
plt.tight_layout()
plt.show()
#%%
df_balanced.shape
#%%
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
import numpy as np

print("Запуск GridSearch для SVM...")

param_grid = {
    'C': [0.1, 1, 10, 100],          # Регуляризация
    'gamma': ['scale', 0.01, 0.1, 1], # Масштаб ядра
    'kernel': ['rbf'],                # Только RBF
    'class_weight': ['balanced']      # Баланс классов
}

svm_grid = GridSearchCV(
    SVC(random_state=42),
    param_grid,
    cv=3,                  # 3 фолда
    scoring='accuracy',    # Метрика
    n_jobs=-1             # Все ядра CPU
)

print("Обучение с подбором параметров")
svm_grid.fit(X_train_small_scaled, y_train_small)

print("Лучшие параметры:", svm_grid.best_params_)
print("Лучшая точность на CV:", svm_grid.best_score_)

best_svm = svm_grid.best_estimator_

y_pred = best_svm.predict(X_test_small_scaled)

print("\nФинальный отчет SVM:")
print(classification_report(y_test_small, y_pred, zero_division=0, digits=3))

#%%
selected_classes = sorted(y_train_small.unique()[:20])
print(f"Выбранные классы: {selected_classes}")

mask = np.isin(y_pred, selected_classes)
y_test_5 = y_test_small[mask]
y_pred_5 = y_pred[mask]

cm = confusion_matrix(y_test_5, y_pred_5, labels=selected_classes)
print("\nМатрица ошибок (ТОЛЬКО 20 классов):")
print(cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=selected_classes,
            yticklabels=selected_classes,
            linewidths=0.5, linecolor='gray')
plt.title("Матрица ошибок SVM (ТОЛЬКО 20 классов)")
plt.xlabel("Предсказано")
plt.ylabel("Истинно")
plt.tight_layout()
plt.show()
#%%
print("Запускаем Random Forest без GridSearch...")

# Фиксированные параметры
rf_simple = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    random_state=42,
    n_jobs=-1
)

rf_simple.fit(X_train_small, y_train_small)

y_pred_rf = rf_simple.predict(X_test_small)
print("\nRandom Forest — отчёт классификации:")
print(classification_report(y_test_small, y_pred_rf, zero_division=0))

#%%
selected_classes = sorted(y_test_small.unique()[:20])
print(f"Выбранные классы: {selected_classes}")

mask = np.isin(y_pred_rf, selected_classes)
y_test_5 = y_test_small[mask]
y_pred_5 = y_pred_rf[mask]

cm = confusion_matrix(y_test_5, y_pred_5, labels=selected_classes)
print("\nМатрица ошибок (ТОЛЬКО 20 классов):")
print(cm)

# === КРАСИВАЙ HEATMAP (5x5) ===
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=selected_classes,
            yticklabels=selected_classes,
            linewidths=0.5, linecolor='gray')
plt.title("Матрица ошибок Random Forest (ТОЛЬКО 20 классов)")
plt.xlabel("Предсказано")
plt.ylabel("Истинно")
plt.tight_layout()
plt.show()
#%%
# FEATURE IMPORTANCE
importances = rf_simple.feature_importances_
feature_names = X_train_small.columns

# Сортировка
indices = np.argsort(importances)[::-1]
sorted_features = [feature_names[i] for i in indices]
sorted_importances = importances[indices]

# График
plt.figure(figsize=(10, 7))
bars = plt.barh(range(len(sorted_importances)), sorted_importances, color='#2ca02c', edgecolor='black')

plt.yticks(range(len(sorted_features)), sorted_features, fontsize=11)
plt.xlabel("Важность признака (Gini)", fontsize=12)
plt.title("Feature Importance в Random Forest", fontsize=16, fontweight='bold')
plt.gca().invert_yaxis()  # Лучший сверху

# Цифры
for i, bar in enumerate(bars):
    width = bar.get_width()
    plt.text(width + 0.005, bar.get_y() + bar.get_height()/2.,
             f'{width:.3f}', ha='left', va='center', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.show()
#%%
print("ГРАФИК СРАВНЕНИЯ ТОЧНОСТИ: KNN, SVM, Random Forest")

import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

# Расчет точности
knn_acc = accuracy_score(y_test_small, y_pred_knn)
svm_acc = accuracy_score(y_test_small, y_pred)
rf_acc = accuracy_score(y_test_small, y_pred_rf)

# Отчеты по всем алгоритмам
from sklearn.metrics import classification_report

print("\nKNN — отчёт классификации:")
print(classification_report(y_test_small, y_pred_knn))

print("\nФинальный отчет SVM:")
print(classification_report(y_test_small, y_pred, zero_division=0, digits=3))

print("\nRandom Forest — отчёт классификации:")
print(classification_report(y_test_small, y_pred_rf, zero_division=0))

print(f"\nТочности:")
print(f"KNN: {knn_acc:.3f}")
print(f"SVM: {svm_acc:.3f}")
print(f"Random Forest: {rf_acc:.3f}")

models = ['KNN', 'SVM', 'Random Forest']
acc_values = [knn_acc, svm_acc, rf_acc]

plt.figure(figsize=(10, 6))
bars = plt.bar(models, acc_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'],
               edgecolor='black', linewidth=1.2)

# Цифры на барах
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.3f}', ha='center', va='bottom', fontsize=12, fontweight='bold')

plt.ylim(0, 1)
plt.title("Сравнение точности: KNN, SVM, Random Forest", fontsize=16, fontweight='bold')
plt.ylabel("Accuracy", fontsize=12)
plt.xlabel("Модель", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()
